## 第五章 神经网络

**01 异或（XOR）问题为什么不能用单个感知器解决？**  
- [ ] A. 因为单个感知器是非线性模型  
- [ ] B. 因为XOR问题不是分类问题  
- [ ] C. 因为XOR问题太复杂  
- [x] D. 因为单个感知器无法处理非线性关系  

**02 以下哪种方法可以用于神经网络的优化？**  
- [ ] A. 随机梯度下降（SGD）  
- [ ] B. 牛顿法  
- [ ] C. 拟牛顿法（如BFGS）  
- [x] D. 以上都可以  

**03 在神经网络中，激活函数的作用是什么？**  
- [x] A. 增加网络的非线性  
- [ ] B. 加快训练速度  
- [ ] C. 减少过拟合  
- [ ] D. 提高准确率  

**04 在神经网络训练中，过拟合可以通过什么方法缓解？**  
- [ ] A. 增加数据集大小  
- [ ] B. 使用正则化  
- [ ] C. 减少网络层数  
- [x] D. 以上都可以  

**05 [多选]感知器能够处理哪些类型的逻辑运算？**  
- [x] A. 与（AND）  
- [x] B. 或（OR）  
- [x] C. 非（NOT）  
- [ ] D. 异或（XOR）  

**06 感知器是一种线性分类模型。**  
- [x] A. 正确  
- [ ] B. 错误  

**07 感知器学习过程是通过不断调整权重和偏置来最小化分类误差。**  
- [x] A. 正确  
- [ ] B. 错误  

**08 神经网络的隐藏层层数越多，网络的性能就一定越好。**  
- [ ] A. 正确  
- [x] B. 错误  

**09 神经网络的训练过程中，损失函数用于衡量网络的输出与期望输出之间的差距。**  
- [x] A. 正确  
- [ ] B. 错误  

**10 在神经网络的训练过程中，______算法是一种常用的优化算法，用于调整权重以最小化损失函数。**  
<details><summary>点击显示答案</summary>
梯度下降法
</details>

**11 简述感知器的基本原理。**  
<details><summary>点击显示答案</summary>
感知器对输入向量 **x** 与权重向量 **w** 做点积并加上偏置 **b**，计算  
$$z = \mathbf{w}\cdot\mathbf{x} + b$$  
然后通过阶跃激活函数输出二值决策（**y** = 1 或 **y** = 0），对线性可分数据进行分类。
</details>

**12 感知器学习过程中的权重调整是如何进行的？**  
<details><summary>点击显示答案</summary>
按感知器学习规则更新：  
$$\Delta w_i = \eta\,(d - y)\,x_i,\quad \Delta b = \eta\,(d - y)$$  
其中 $\eta$ 为学习率，$d$ 为目标标签，$y$ 为当前输出。
</details>

**13 前馈神经网络的基本结构是什么？**  
<details><summary>点击显示答案</summary>
由输入层、一个或多个隐藏层和输出层按序组成，各层之间通常是全连接（Dense），信息沿前向（Feedforward）方向传播。
</details>
